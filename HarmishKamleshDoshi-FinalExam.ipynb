{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ddd06f7-3837-4ef9-8d70-cfe075736595",
   "metadata": {},
   "source": [
    "# IST769 Final Exam\n",
    "\n",
    "**INSTRUCTIONS FOR HIGHEST GRADE POSSIBLE**\n",
    "\n",
    "Unless you are explicitly instructed otherwise, answer each of the following using PySpark / Spark SQL. For any queries you write make sure to include a `printSchema()` and sample(s) of the output which clearly demonstrates the code is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c187379-6afa-41cf-bcda-92c04eea5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR NAME ========> Harmish Kamlesh Doshi  \n",
    "# YOUR SU EMAIL ====>  208610770"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25feebd0-d09b-4233-b9af-ec965875930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo cp /home/jovyan/work/jars/neo4j-connector-apache-spark_2.12-4.1.0_for_spark_3.jar /usr/local/spark/jars/neo4j-connector-apache-spark_2.12-4.1.0_for_spark_3.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4308c98a-a418-4120-9ee7-05992d21e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q cassandra-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c73c8d6-8ab6-44a8-8a78-51598b8c07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the required libraries.\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.types import *\n",
    "from cassandra.cluster import Cluster\n",
    "from pyspark.sql.functions import array_contains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91718b91-ceae-416d-b96c-053a5d844676",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "In the cell below configure a spark session that is configured to connect to `mongodb`, `minio`, `cassandra`, '`elasticsearch` and `neo4j`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5ecf9f-0798-4bc9-8896-229a0faade48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      "com.datastax.spark#spark-cassandra-connector-assembly_2.12 added as a dependency\n",
      "org.elasticsearch#elasticsearch-spark-20_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-d976ec0f-c43e-4997-9fb3-f617a40925df;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.1.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.271 in central\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-assembly_2.12;3.1.0 in central\n",
      "\tfound org.elasticsearch#elasticsearch-spark-20_2.12;7.15.0 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.6 in central\n",
      "\tfound commons-logging#commons-logging;1.1.1 in central\n",
      "\tfound javax.xml.bind#jaxb-api;2.3.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java;2.5.0 in central\n",
      "\tfound org.apache.spark#spark-yarn_2.12;2.4.4 in central\n",
      ":: resolution report :: resolve 1215ms :: artifacts dl 11ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.271 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-assembly_2.12;3.1.0 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;2.5.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.1 from central in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.1.2 from central in [default]\n",
      "\torg.apache.spark#spark-yarn_2.12;2.4.4 from central in [default]\n",
      "\torg.elasticsearch#elasticsearch-spark-20_2.12;7.15.0 from central in [default]\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.8 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.6 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   14  |   0   |   0   |   0   ||   8   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-d976ec0f-c43e-4997-9fb3-f617a40925df\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 8 already retrieved (0kB/14ms)\n",
      "24/04/27 00:21:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "#1 Spark session\n",
    "\n",
    "#Credentials:\n",
    "#Master Password:\n",
    "passwd = \"SU2orange!\"\n",
    "\n",
    "#MinIO:\n",
    "minio_user = \"minio\"\n",
    "##Bucket Details:\n",
    "s3_bucket = \"enrollments\"\n",
    "s3_server = \"http://minio:9000\"\n",
    "s3_access_key = minio_user\n",
    "s3_secret_key = passwd\n",
    "\n",
    "#Mongo:\n",
    "mongo_pass = \"mongopw\"\n",
    "mongo_user = \"admin\"\n",
    "mongo_uri = f\"mongodb://{mongo_user}:{mongo_pass}@mongo:27017/admin?authSource=admin\"\n",
    "\n",
    "#Elastic Search and Kibana Credentials:\n",
    "kibana_user = 'elastic'\n",
    "elastic_host = \"elasticsearch\"\n",
    "elastic_port = \"9200\"\n",
    "\n",
    "#Cassandra:\n",
    "cassandra_host = \"cassandra\"\n",
    "\n",
    "#Neo4j:\n",
    "bolt_url = \"bolt://neo4j:7687\"\n",
    "\n",
    "\n",
    "#Installing all required jars\n",
    "jars = [\n",
    "    \"org.apache.hadoop:hadoop-aws:3.1.2\" #MinIO Jar\n",
    "    ,\"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\" #Mongo jar\n",
    "    ,\"com.datastax.spark:spark-cassandra-connector-assembly_2.12:3.1.0\" #Cassandra Jar\n",
    "    ,\"org.elasticsearch:elasticsearch-spark-20_2.12:7.15.0\" #Elastic search Jar\n",
    "    ]\n",
    "\n",
    "\n",
    "#Configuring Spark Session and building APP:\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "        .config(\"spark.jars.packages\",\",\".join(jars) )\\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", s3_server ) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", s3_access_key) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", s3_secret_key) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.fast.upload\", True) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", True) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.mongodb.input.uri\", mongo_uri) \\\n",
    "        .config(\"spark.mongodb.output.uri\", mongo_uri) \\\n",
    "        .config(\"spark.cassandra.connection.host\", cassandra_host) \\\n",
    "        .config(\"spark.es.nodes\", elastic_host) \\\n",
    "        .config(\"spark.es.port\",elastic_port) \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\") # Keeps the noise down!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee055a5-7a8f-4739-a3f5-a52d981ea05e",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Demonstrate you can read the process-oriented data `enrollments` and `sections` from `minio` using PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d50367be-c7ac-43b0-b820-54e4b7d83c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- enrollments_term: integer (nullable = true)\n",
      " |-- course_enrollment: integer (nullable = true)\n",
      " |-- enrollments_course: string (nullable = true)\n",
      " |-- enrollments_section: string (nullable = true)\n",
      " |-- enrollments_student_id: string (nullable = true)\n",
      " |-- enrollments_grade: string (nullable = true)\n",
      " |-- enrollments_grade_points: float (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+------------------+-------------------+----------------------+-----------------+------------------------+\n",
      "|enrollments_term|course_enrollment|enrollments_course|enrollments_section|enrollments_student_id|enrollments_grade|enrollments_grade_points|\n",
      "+----------------+-----------------+------------------+-------------------+----------------------+-----------------+------------------------+\n",
      "|            1221|                1|            IST659|               M001|           orenjouglad|                C|                     2.0|\n",
      "|            1221|                2|            IST659|               M001|           billmelator|                A|                     4.0|\n",
      "|            1221|                3|            IST659|               M001|            morrisless|                A|                     4.0|\n",
      "|            1221|                4|            IST659|               M001|     amberwavesofgrain|               A-|                   3.667|\n",
      "|            1221|                5|            IST659|               M001|              abbykuss|                A|                     4.0|\n",
      "+----------------+-----------------+------------------+-------------------+----------------------+-----------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "743"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2a enrollments\n",
    "# Define the schema for enrollments data\n",
    "enrollments = StructType([StructField(\"enrollments_term\",IntegerType()),\n",
    "                          StructField(\"course_enrollment\",IntegerType()),\n",
    "                          StructField(\"enrollments_course\",StringType()),\n",
    "                          StructField(\"enrollments_section\",StringType()),\n",
    "                          StructField(\"enrollments_student_id\",StringType()),\n",
    "                          StructField(\"enrollments_grade\",StringType()),\n",
    "                          StructField(\"enrollments_grade_points\",FloatType())\n",
    "                        ])\n",
    "\n",
    "# Read enrollments data from CSV file on MinIO\n",
    "enrollments_df = spark.read.csv(f\"s3a://{s3_bucket}/enrollments.csv\",schema = enrollments, sep = \",\", header = True)\n",
    "# Print schema and show sample records\n",
    "enrollments_df.printSchema()\n",
    "enrollments_df.show(5)\n",
    "# Count the number of records in the enrollments DataFrame\n",
    "enrollments_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b415479-5acf-42dc-b535-c80bc62d239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sections_term: integer (nullable = true)\n",
      " |-- sections_course: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- sections_enrollment: integer (nullable = true)\n",
      " |-- sections_capacity: integer (nullable = true)\n",
      "\n",
      "+-------------+---------------+-------+-------------------+-----------------+\n",
      "|sections_term|sections_course|section|sections_enrollment|sections_capacity|\n",
      "+-------------+---------------+-------+-------------------+-----------------+\n",
      "|         1221|         IST659|   M001|                 20|               20|\n",
      "|         1221|         IST659|   M002|                 20|               20|\n",
      "|         1221|         IST722|   M001|                 25|               28|\n",
      "|         1221|         IST615|   M001|                 22|               28|\n",
      "|         1221|         IST621|   M001|                 22|               24|\n",
      "+-------------+---------------+-------+-------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2b sections\n",
    "# Define the schema for sections data\n",
    "sections = StructType([StructField(\"sections_term\",IntegerType()),\n",
    "                        StructField(\"sections_course\",StringType()),\n",
    "                        StructField(\"section\",StringType()),\n",
    "                        StructField(\"sections_enrollment\",IntegerType()),\n",
    "                        StructField(\"sections_capacity\",IntegerType())])\n",
    "# Read sections data from CSV file on MinIO\n",
    "sections_df = spark.read.csv(f\"s3a://{s3_bucket}/sections.csv\",schema = sections, sep = \",\",header = True)\n",
    "# Print schema and show sample records\n",
    "sections_df.printSchema()\n",
    "sections_df.show(5)\n",
    "# Count the number of records in the enrollments DataFrame\n",
    "sections_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74906498-d775-451f-befd-5e88595b7009",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Demonstrate you can read the reference-oriented data `terms`, `students`, `courses`, and `program` reference data from `MongoDb` using PySpark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f928bc1-1306-42d7-a073-c7673dde4f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- term_code: string (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n",
      "+----+-------------+---------+-----------+--------+----+\n",
      "| _id|academic_year|term_code|  term_name|semester|year|\n",
      "+----+-------------+---------+-----------+--------+----+\n",
      "|1221|    2021-2022|     1221|  Fall 2021|    Fall|2021|\n",
      "|1222|    2021-2022|     1222|Spring 2022|  Spring|2022|\n",
      "|1231|    2022-2023|     1231|  Fall 2022|    Fall|2022|\n",
      "|1232|    2022-2023|     1232|Spring 2023|  Spring|2023|\n",
      "+----+-------------+---------+-----------+--------+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3a terms \n",
    "# Read terms data from MongoDB collection\n",
    "terms_df = spark.read.format(\"mongo\").option(\"database\",\"ischooldb\").option(\"collection\",\"terms\").load()\n",
    "# Rename columns for clarity\n",
    "terms_df = terms_df.withColumnRenamed(\"name\",\"term_name\")\\\n",
    "                    .withColumnRenamed(\"code\",\"term_code\")\n",
    "# Print schema and show sample records\n",
    "terms_df.printSchema()\n",
    "terms_df.show(5)\n",
    "# Count the number of records in the terms DataFrame\n",
    "terms_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b917eaca-2e3e-45ab-84aa-bc2f07bf6e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- course_code: string (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- elective_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- key_assignments: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- prerequisites: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- required_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+------+-----------+--------------+--------------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "|   _id|course_code|course_credits|  course_description|elective_in_programs| key_assignments|         course_name|prerequisites|required_in_programs|\n",
      "+------+-----------+--------------+--------------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "|IST659|     IST659|             3|Definition, devel...|                  []|       [project]|Data Administrati...|           []|            [IS, DS]|\n",
      "|IST722|     IST722|             3|Introduction to c...|                [IS]| [project, exam]|    Data Warehousing|     [IST659]|                  []|\n",
      "|IST769|     IST769|             3|Analyze relationa...|                [DS]| [project, exam]|Advanced Big Data...|     [IST659]|                  []|\n",
      "|IST615|     IST615|             3|Cloud services cr...|                  []|[project, paper]|    Cloud Management|           []|            [IS, DS]|\n",
      "|IST714|     IST714|             3|Advanced, lab-bas...|            [IS, DS]|       [project]|  Cloud Architecture|     [IST615]|                  []|\n",
      "+------+-----------+--------------+--------------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3b courses\n",
    "courses_df = spark.read.format(\"mongo\").option(\"database\",\"ischooldb\").option(\"collection\",\"courses\").load()\n",
    "courses_df = courses_df.withColumnRenamed(\"name\",\"course_name\")\\\n",
    "                       .withColumnRenamed(\"code\",\"course_code\")\\\n",
    "                       .withColumnRenamed(\"credits\",\"course_credits\")\\\n",
    "                       .withColumnRenamed(\"description\",\"course_description\")\n",
    "courses_df.printSchema()\n",
    "courses_df.show(5)\n",
    "courses_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f483a03-3da6-4efa-95d7-06c82e556400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- program_code: string (nullable = true)\n",
      " |-- program_credits: integer (nullable = true)\n",
      " |-- elective_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- program_name: string (nullable = true)\n",
      " |-- required_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n",
      "+---+------------+---------------+--------------------+--------------------+--------------------+-----------+\n",
      "|_id|program_code|program_credits|    elective_courses|        program_name|    required_courses|       type|\n",
      "+---+------------+---------------+--------------------+--------------------+--------------------+-----------+\n",
      "| IS|          IS|             36|[IST722, IST714, ...| Information Systems|[IST659, IST615, ...|    Masters|\n",
      "| DS|          DS|             34|    [IST769, IST714]|        Data Science|[IST659, IST615, ...|    Masters|\n",
      "|BDC|         BDC|              9|                null|Data Engineering ...|[IST659, IST722, ...|Certificate|\n",
      "|CCC|         CCC|              9|                null|Cloud Computing C...|[IST621, IST615, ...|Certificate|\n",
      "|MLC|         MLC|              9|                null|Machine Learning ...|[IST687, IST707, ...|Certificate|\n",
      "+---+------------+---------------+--------------------+--------------------+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3c Programs\n",
    "programs_df = spark.read.format(\"mongo\").option(\"database\",\"ischooldb\").option(\"collection\",\"programs\").load()\n",
    "programs_df = programs_df.withColumnRenamed(\"code\",\"program_code\")\\\n",
    "                         .withColumnRenamed(\"credits\",\"program_credits\")\\\n",
    "                        .withColumnRenamed(\"name\",\"program_name\")\n",
    "programs_df.printSchema()\n",
    "programs_df.show(5)\n",
    "programs_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88d87294-61eb-4dd4-8b7a-5c280b6b7c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- student_name: string (nullable = true)\n",
      " |-- student_enrolled_program: string (nullable = true)\n",
      "\n",
      "+------------+-------------+------------------------+\n",
      "|         _id| student_name|student_enrolled_program|\n",
      "+------------+-------------+------------------------+\n",
      "|    abbykuss|    Abby Kuss|                      DS|\n",
      "|  adamantium|  Adam Antium|                      IS|\n",
      "|   addieowse|   Addie Owse|                      IS|\n",
      "|aidensomewun|Aiden Somewun|                      IS|\n",
      "|aidenknowone|Aiden Knowone|                      DS|\n",
      "+------------+-------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3d students\n",
    "students_df = spark.read.format(\"mongo\").option(\"database\",\"ischooldb\").option(\"collection\",\"students\").load()\n",
    "students_df = students_df.withColumnRenamed(\"name\",\"student_name\")\\\n",
    "                         .withColumnRenamed(\"program\",\"student_enrolled_program\")\n",
    "students_df.printSchema()\n",
    "students_df.show(5)\n",
    "students_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abfca28-8272-46ee-b98c-6a263be01c56",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Prepare the `section` data for loading into `cassandra` and `elasticsearch` with Spark or Spark SQL. Just PREPARE it do not LOAD it. Remember that we want this data to be as wide as possible, so include all relevant reference data. For example, the `section` data should include `term` attributes like `year`,  `academic year`, etc... and from `course`, attributes like `credits`, `name`, `prerequisites`, etc... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ce2a89d-9333-4630-91b4-b54012fe4183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sections_term: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- sections_course: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- prerequisites: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- required_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- elective_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- key_assignments: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- sections_capacity: integer (nullable = true)\n",
      " |-- sections_enrollment: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+--------+---------+-------------+---------------+----------------+--------------------+--------------+-------------+--------------------+--------------------+----------------+-------+-----------------+-------------------+\n",
      "|sections_term|year|semester|term_name|academic_year|sections_course|     course_name|  course_description|course_credits|prerequisites|required_in_programs|elective_in_programs| key_assignments|section|sections_capacity|sections_enrollment|\n",
      "+-------------+----+--------+---------+-------------+---------------+----------------+--------------------+--------------+-------------+--------------------+--------------------+----------------+-------+-----------------+-------------------+\n",
      "|         1221|2021|    Fall|Fall 2021|    2021-2022|         IST615|Cloud Management|Cloud services cr...|             3|           []|            [IS, DS]|                  []|[project, paper]|   M001|               28|                 22|\n",
      "+-------------+----+--------+---------+-------------+---------------+----------------+--------------------+--------------+-------------+--------------------+--------------------+----------------+-------+-----------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 wide_sections\n",
    "# Join sections, terms, and courses DataFrames to create wide_sections DataFrame\n",
    "q4_sections_df = sections_df\\\n",
    "    .join(terms_df, how = 'inner', on  = sections_df.sections_term == terms_df._id)\\\n",
    "    .join(courses_df, how = 'inner',on = sections_df.sections_course == courses_df._id)\\\n",
    "    .select('sections_term',\n",
    "             'year','semester','term_name','academic_year',\n",
    "             'sections_course',\n",
    "             'course_name','course_description','course_credits','prerequisites','required_in_programs','elective_in_programs','key_assignments',\n",
    "             'section','sections_capacity','sections_enrollment'\n",
    "           )\\\n",
    "    .orderBy([\"year\",\"sections_course\",\"section\"])\n",
    "# Print schema and show sample records\n",
    "q4_sections_df.printSchema()\n",
    "q4_sections_df.show(1)\n",
    "# Count the number of records in the wide_sections DataFrame\n",
    "q4_sections_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f972cf-8ab1-48fe-b2ff-607acc11e05d",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Use the `cassandra-driver` example from class to write python code to connect to cassandra from within Jupyter and create a keyspace named `ischooldb`. Design a cassandra table called `sections` to store the data from question 4. Appropriate key design is important! Please explain your justification for key below your table definition. Provide clear evidence that your table was created by querying the empty table in spark and use `printSchema()` to show the schema. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64dd6958-1183-46de-a8df-309af4796510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = false)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- sections_course: string (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- elective_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- key_assignments: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- prerequisites: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- required_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- sections_capacity: integer (nullable = true)\n",
      " |-- sections_enrollment: integer (nullable = true)\n",
      " |-- sections_term: integer (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      "\n",
      "+----+--------+---------------+-------------+--------------+--------------------+----------------+--------------------+----------------+-------------+--------------------+-------+-----------------+-------------------+-------------+---------+\n",
      "|year|semester|sections_course|academic_year|course_credits|  course_description|     course_name|elective_in_programs| key_assignments|prerequisites|required_in_programs|section|sections_capacity|sections_enrollment|sections_term|term_name|\n",
      "+----+--------+---------------+-------------+--------------+--------------------+----------------+--------------------+----------------+-------------+--------------------+-------+-----------------+-------------------+-------------+---------+\n",
      "|2022|    Fall|         IST615|    2022-2023|             3|Cloud services cr...|Cloud Management|                  []|[project, paper]|           []|            [IS, DS]|   M001|               24|                 21|         1231|Fall 2022|\n",
      "+----+--------+---------------+-------------+--------------+--------------------+----------------+--------------------+----------------+-------------+--------------------+-------+-----------------+-------------------+-------------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#5 create cassandra table for wide_sections\n",
    "#Creating Keyspace & Table in Cassandra.\n",
    "with Cluster([cassandra_host]) as cluster:\n",
    "    session = cluster.connect()\n",
    "    session.execute(\"CREATE KEYSPACE IF NOT EXISTS ischooldb WITH replication={ 'class': 'SimpleStrategy', 'replication_factor' : 1 };\")\n",
    "    session.execute(\"CREATE TABLE IF NOT EXISTS ischooldb.sections (\\\n",
    "                    sections_term int,\\\n",
    "                    year int,\\\n",
    "                    semester varchar,\\\n",
    "                    term_name varchar,\\\n",
    "                    academic_year varchar,\\\n",
    "                    sections_course varchar,\\\n",
    "                    course_name varchar,\\\n",
    "                    course_description varchar,\\\n",
    "                    course_credits int,\\\n",
    "                    prerequisites LIST<text>,\\\n",
    "                    required_in_programs LIST<text>,\\\n",
    "                    elective_in_programs LIST<text>,\\\n",
    "                    key_assignments LIST<text>,\\\n",
    "                    section varchar,\\\n",
    "                    sections_capacity int,\\\n",
    "                    sections_enrollment int,\\\n",
    "                    primary key ((year),semester,sections_course));\")\n",
    "    \n",
    "q5_sections_df = spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "    .options(table = \"sections\",keyspace = \"ischooldb\")\\\n",
    "    .load()\n",
    "\n",
    "q5_sections_df.printSchema()\n",
    "q5_sections_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebdf6f9-f76b-452c-9673-df7a9e0f2459",
   "metadata": {},
   "source": [
    "**Partition Key (year):** Using the year as the partition key allows for data distribution across different nodes based on the year, which can help distribute the workload evenly and improve query performance.\n",
    "**Clustering Columns (semester, sections_course):** Clustering columns define the uniqueness of each row within a partition. In this case, combining semester and sections_course ensures that each row within a year partition is unique. It also allows for efficient retrieval of data within a specific year by leveraging the clustering order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee71b3b5-03d7-456d-a64f-f3c5f0c93836",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Load the data frame you created in question 4 into the `cassandra` table you created in question 5. Demonstrate the data is in the table by querying back it with PySpark. Make sure you can run the code multiple times and each time it replaces the existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59e9aac0-da49-4c82-8e3f-184b5f1d9eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = false)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- sections_course: string (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- elective_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- key_assignments: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- prerequisites: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- required_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- sections_capacity: integer (nullable = true)\n",
      " |-- sections_enrollment: integer (nullable = true)\n",
      " |-- sections_term: integer (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      "\n",
      "+----+--------+---------------+-------------+--------------+--------------------+----------------+--------------------+----------------+-------------+--------------------+-------+-----------------+-------------------+-------------+---------+\n",
      "|year|semester|sections_course|academic_year|course_credits|  course_description|     course_name|elective_in_programs| key_assignments|prerequisites|required_in_programs|section|sections_capacity|sections_enrollment|sections_term|term_name|\n",
      "+----+--------+---------------+-------------+--------------+--------------------+----------------+--------------------+----------------+-------------+--------------------+-------+-----------------+-------------------+-------------+---------+\n",
      "|2021|    Fall|         IST615|    2021-2022|             3|Cloud services cr...|Cloud Management|                  []|[project, paper]|           []|            [IS, DS]|   M001|               28|                 22|         1221|Fall 2021|\n",
      "+----+--------+---------------+-------------+--------------+--------------------+----------------+--------------------+----------------+-------------+--------------------+-------+-----------------+-------------------+-------------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6 load wide_sections into cassandra\n",
    "# Writing wide sections DataFrame to Cassandra\n",
    "q4_sections_df.write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "  .mode(\"Append\")\\\n",
    "  .option(\"table\", \"sections\")\\\n",
    "  .option(\"keyspace\",\"ischooldb\")\\\n",
    "  .save()\n",
    "\n",
    "# #Reading back the data from cassandra to verify data is loaded correctly.\n",
    "q5_sections_df = spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "    .options(table = \"sections\",keyspace = \"ischooldb\")\\\n",
    "    .load()\n",
    "\n",
    "q5_sections_df.printSchema()\n",
    "q5_sections_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a052fbcc-b7cc-4fa7-ba5d-09b3066c8b96",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Since we did not learn how to create a custom elasticsearch mapping, before you can load the data into `elasticsearch` you will need to flatten the nested data. For example, `course_is_elective_in_programs` should generate 2 columns `course_is_elective_for_IS` and `course_is_elective_for_DS`. You'll need to repeat this step for `course_is_required_in_programs`. Omit the `course_prerequisites` and `course_key_assignments` column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee029f8a-d76c-4b4d-a653-d68c51c1b801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sections_term: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- sections_course: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- sections_capacity: integer (nullable = true)\n",
      " |-- sections_enrollment: integer (nullable = true)\n",
      " |-- course_is_elective_for_IS: string (nullable = false)\n",
      " |-- course_is_elective_for_DS: string (nullable = false)\n",
      " |-- course_is_required_for_IS: string (nullable = false)\n",
      " |-- course_is_required_for_DS: string (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+--------+---------+-------------+---------------+----------------+--------------------+--------------+-------+-----------------+-------------------+-------------------------+-------------------------+-------------------------+-------------------------+\n",
      "|sections_term|year|semester|term_name|academic_year|sections_course|     course_name|  course_description|course_credits|section|sections_capacity|sections_enrollment|course_is_elective_for_IS|course_is_elective_for_DS|course_is_required_for_IS|course_is_required_for_DS|\n",
      "+-------------+----+--------+---------+-------------+---------------+----------------+--------------------+--------------+-------+-----------------+-------------------+-------------------------+-------------------------+-------------------------+-------------------------+\n",
      "|         1221|2021|    Fall|Fall 2021|    2021-2022|         IST615|Cloud Management|Cloud services cr...|             3|   M001|               28|                 22|                       no|                       no|                      yes|                      yes|\n",
      "+-------------+----+--------+---------+-------------+---------------+----------------+--------------------+--------------+-------+-----------------+-------------------+-------------------------+-------------------------+-------------------------+-------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten nested data and derive new columns for Elasticsearch indexing.\n",
    "# We are checking if the course is elective for Information Systems (IS) or Data Science (DS) programs based on the presence of these programs in the 'elective_in_programs' column.\n",
    "# If the program is found, we label the course as 'yes' for the respective program; otherwise, we label it as 'no'.\n",
    "q7_sections_flatten = q4_sections_df.withColumn(\"course_is_elective_for_IS\", \n",
    "                                                when(array_contains(q4_sections_df.elective_in_programs, \"IS\"), 'yes').otherwise(\"no\")) \\\n",
    "                                    .withColumn(\"course_is_elective_for_DS\", \n",
    "                                                when(array_contains(q4_sections_df.elective_in_programs, \"DS\"), 'yes').otherwise(\"no\")) \\\n",
    "                                    .withColumn(\"course_is_required_for_IS\", \n",
    "                                                when(array_contains(q4_sections_df.required_in_programs, \"IS\"), 'yes').otherwise(\"no\")) \\\n",
    "                                    .withColumn(\"course_is_required_for_DS\", \n",
    "                                                when(array_contains(q4_sections_df.required_in_programs, \"DS\"), 'yes').otherwise(\"no\")) \\\n",
    "                                    .drop(\"prerequisites\", \"elective_in_programs\", \"required_in_programs\",\"key_assignments\")\n",
    "\n",
    "q7_sections_flatten = q7_sections_flatten.dropDuplicates() #Just to drop any duplicate values.\n",
    "q7_sections_flatten.printSchema()\n",
    "q7_sections_flatten.show(1)\n",
    "q7_sections_flatten.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd3d88-efe9-4d0c-90ce-941ef6de84e2",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Load the data frame you created in question 7 into `elasticsearch`, under the index `sections`.  Demonstrate the data is in the index by querying back it with PySpark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39d2c484-7857-4064-a60c-c1ec0004b370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- capacity: long (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- course_credits: long (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- course_is_elective_for_DS: string (nullable = true)\n",
      " |-- course_is_elective_for_IS: string (nullable = true)\n",
      " |-- course_is_required_for_DS: string (nullable = true)\n",
      " |-- course_is_required_for_IS: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- credits: long (nullable = true)\n",
      " |-- enrollment: long (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- sections_capacity: long (nullable = true)\n",
      " |-- sections_course: string (nullable = true)\n",
      " |-- sections_enrollment: long (nullable = true)\n",
      " |-- sections_term: long (nullable = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- term: long (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n",
      "+-------------+--------+------+--------------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+----------------+-------+----------+-------+-----------------+---------------+-------------------+-------------+--------+----+---------+----+\n",
      "|academic_year|capacity|course|course_credits|  course_description|course_is_elective_for_DS|course_is_elective_for_IS|course_is_required_for_DS|course_is_required_for_IS|     course_name|credits|enrollment|section|sections_capacity|sections_course|sections_enrollment|sections_term|semester|term|term_name|year|\n",
      "+-------------+--------+------+--------------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+----------------+-------+----------+-------+-----------------+---------------+-------------------+-------------+--------+----+---------+----+\n",
      "|    2021-2022|    null|  null|             3|Cloud services cr...|                       no|                       no|                      yes|                      yes|Cloud Management|   null|      null|   M001|               28|         IST615|                 22|         1221|    Fall|null|Fall 2021|2021|\n",
      "+-------------+--------+------+--------------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+----------------+-------+----------+-------+-----------------+---------------+-------------------+-------------+--------+----+---------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8 load wide_sections_flattened into elasticsearch\n",
    "\n",
    "# Reading and Writing data from  dataframe and saving as an index in elastic search.\n",
    "# Save the flattened wide sections dataframe to Elasticsearch\n",
    "q7_sections_flatten.write.mode(\"Overwrite\").format(\"es\").save(\"sections/_doc\")\n",
    "\n",
    "# Reading back the data from Elasticsearch to verify data is loaded correctly\n",
    "q8_sections_esdf = spark.read.format(\"es\").load(\"sections/_doc\")\n",
    "q8_sections_esdf.printSchema()\n",
    "q8_sections_esdf.show(1)\n",
    "q8_sections_esdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa738b4b-6970-46d4-b5dc-3c766f7fe64b",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Similar to question 4, prepare the `enrollments` for loading into `cassandra` and `elasticsearch` with Spark or Spark SQL. For this wide table we want to include the same reference data for `sections` but include the `student` attributes and the `program` data associated with the student. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84dab444-381f-4a8a-9950-a9b56c0f4fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      " |-- enrollments_term: integer (nullable = true)\n",
      " |-- course_enrollment: integer (nullable = true)\n",
      " |-- enrollments_course: string (nullable = true)\n",
      " |-- enrollments_section: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- sections_capacity: integer (nullable = true)\n",
      " |-- sections_enrollment: integer (nullable = true)\n",
      " |-- course_is_elective_for_IS: string (nullable = false)\n",
      " |-- course_is_elective_for_DS: string (nullable = false)\n",
      " |-- course_is_required_for_IS: string (nullable = false)\n",
      " |-- course_is_required_for_DS: string (nullable = false)\n",
      " |-- enrollments_student_id: string (nullable = true)\n",
      " |-- student_name: string (nullable = true)\n",
      " |-- enrollments_grade: string (nullable = true)\n",
      " |-- enrollments_grade_points: float (nullable = true)\n",
      " |-- student_enrolled_program: string (nullable = true)\n",
      " |-- program_name: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- program_credits: integer (nullable = true)\n",
      " |-- required_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- elective_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+--------+---------+----------------+-----------------+------------------+-------------------+----------------+--------------------+--------------+-----------------+-------------------+-------------------------+-------------------------+-------------------------+-------------------------+----------------------+------------+-----------------+------------------------+------------------------+------------+-------+---------------+--------------------+----------------+\n",
      "|academic_year|year|semester|term_name|enrollments_term|course_enrollment|enrollments_course|enrollments_section|     course_name|  course_description|course_credits|sections_capacity|sections_enrollment|course_is_elective_for_IS|course_is_elective_for_DS|course_is_required_for_IS|course_is_required_for_DS|enrollments_student_id|student_name|enrollments_grade|enrollments_grade_points|student_enrolled_program|program_name|   type|program_credits|    required_courses|elective_courses|\n",
      "+-------------+----+--------+---------+----------------+-----------------+------------------+-------------------+----------------+--------------------+--------------+-----------------+-------------------+-------------------------+-------------------------+-------------------------+-------------------------+----------------------+------------+-----------------+------------------------+------------------------+------------+-------+---------------+--------------------+----------------+\n",
      "|    2022-2023|2022|    Fall|Fall 2022|            1231|               12|            IST615|               M001|Cloud Management|Cloud services cr...|             3|               24|                 21|                       no|                       no|                      yes|                      yes|            artiechoke| Artie Choke|                A|                     4.0|                      DS|Data Science|Masters|             34|[IST659, IST615, ...|[IST769, IST714]|\n",
      "+-------------+----+--------+---------+----------------+-----------------+------------------+-------------------+----------------+--------------------+--------------+-----------------+-------------------+-------------------------+-------------------------+-------------------------+-------------------------+----------------------+------------+-----------------+------------------------+------------------------+------------+-------+---------------+--------------------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "743"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9 - enrollments\n",
    "# Joining enrollment data with wide flattened sections, students, and programs dataframes to enrich enrollment information\n",
    "# We perform an inner join on the enrollment term, course, and section to match with the respective section details.\n",
    "# We then join the result with students and programs dataframes based on student ID and enrolled program ID, respectively.\n",
    "# Selecting relevant columns to include in the final enrollment dataframe for Elasticsearch indexing.\n",
    "q9_enrollments_df = enrollments_df.join(q7_sections_flatten, how = 'inner', on =(enrollments_df.enrollments_term == q7_sections_flatten.sections_term)&\\\n",
    "                                                (enrollments_df.enrollments_course == q7_sections_flatten.sections_course)&\\\n",
    "                                                (enrollments_df.enrollments_section == q7_sections_flatten.section))\\\n",
    "                .join(students_df,how = 'inner', on = enrollments_df.enrollments_student_id == students_df._id)\\\n",
    "                .join(programs_df,how = 'inner', on = students_df.student_enrolled_program == programs_df._id)\\\n",
    "                .select(\"academic_year\",\n",
    "                        \"year\",\n",
    "                        \"semester\",\n",
    "                        \"term_name\",\n",
    "                        \"enrollments_term\",\n",
    "                        \"course_enrollment\",\n",
    "                        \"enrollments_course\",\n",
    "                        \"enrollments_section\",\n",
    "                        \"course_name\",\n",
    "                        \"course_description\",\n",
    "                        \"course_credits\",\n",
    "                        \"sections_capacity\",\n",
    "                        \"sections_enrollment\",\n",
    "                        \"course_is_elective_for_IS\",\n",
    "                        \"course_is_elective_for_DS\",\n",
    "                        \"course_is_required_for_IS\",\n",
    "                        \"course_is_required_for_DS\",\n",
    "                        \"enrollments_student_id\",\n",
    "                        \"student_name\",\n",
    "                        \"enrollments_grade\",\n",
    "                        \"enrollments_grade_points\",\n",
    "                        \"student_enrolled_program\",\n",
    "                        \"program_name\",\n",
    "                        \"type\",\n",
    "                        \"program_credits\",\n",
    "                        \"required_courses\",\n",
    "                        \"elective_courses\"\n",
    "                        )\n",
    "q9_enrollments_df.printSchema()\n",
    "q9_enrollments_df.show(1)\n",
    "q9_enrollments_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae284c8-096a-4987-98cf-0800cedced12",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Load the data frame you created in question 8 into `elasticsearch`, under the index `enrollments`. This time, just Omit all array types to make the problem simpler (`elective_courses`, `key_assignments`, `course_prerequisites`, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a42dedc-62c4-4b83-b431-2a3474834901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- academic_year: string (nullable = true)\n",
      " |-- course_credits: long (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- course_enrollment: long (nullable = true)\n",
      " |-- course_is_elective_for_DS: string (nullable = true)\n",
      " |-- course_is_elective_for_IS: string (nullable = true)\n",
      " |-- course_is_required_for_DS: string (nullable = true)\n",
      " |-- course_is_required_for_IS: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- enrollments_course: string (nullable = true)\n",
      " |-- enrollments_grade: string (nullable = true)\n",
      " |-- enrollments_grade_points: float (nullable = true)\n",
      " |-- enrollments_section: string (nullable = true)\n",
      " |-- enrollments_student_id: string (nullable = true)\n",
      " |-- enrollments_term: long (nullable = true)\n",
      " |-- program_credits: long (nullable = true)\n",
      " |-- program_name: string (nullable = true)\n",
      " |-- sections_capacity: long (nullable = true)\n",
      " |-- sections_enrollment: long (nullable = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- student_enrolled_program: string (nullable = true)\n",
      " |-- student_name: string (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n",
      "+-------------+--------------+--------------------+-----------------+-------------------------+-------------------------+-------------------------+-------------------------+----------------+------------------+-----------------+------------------------+-------------------+----------------------+----------------+---------------+------------+-----------------+-------------------+--------+------------------------+------------+---------+-------+----+\n",
      "|academic_year|course_credits|  course_description|course_enrollment|course_is_elective_for_DS|course_is_elective_for_IS|course_is_required_for_DS|course_is_required_for_IS|     course_name|enrollments_course|enrollments_grade|enrollments_grade_points|enrollments_section|enrollments_student_id|enrollments_term|program_credits|program_name|sections_capacity|sections_enrollment|semester|student_enrolled_program|student_name|term_name|   type|year|\n",
      "+-------------+--------------+--------------------+-----------------+-------------------------+-------------------------+-------------------------+-------------------------+----------------+------------------+-----------------+------------------------+-------------------+----------------------+----------------+---------------+------------+-----------------+-------------------+--------+------------------------+------------+---------+-------+----+\n",
      "|    2022-2023|             3|Cloud services cr...|               12|                       no|                       no|                      yes|                      yes|Cloud Management|            IST615|                A|                     4.0|               M001|            artiechoke|            1231|             34|Data Science|               24|                 21|    Fall|                      DS| Artie Choke|Fall 2022|Masters|2022|\n",
      "+-------------+--------------+--------------------+-----------------+-------------------------+-------------------------+-------------------------+-------------------------+----------------+------------------+-----------------+------------------------+-------------------+----------------------+----------------+---------------+------------+-----------------+-------------------+--------+------------------------+------------+---------+-------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "743"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 wide_enrollments to elastic search\n",
    "q9_enrollments_df1 = q9_enrollments_df.drop(\"required_courses\",\"elective_courses\")\n",
    "#Reading and Writing data from the directory to dataframe.\n",
    "q9_enrollments_df1.write.mode(\"Overwrite\").format(\"es\").save(\"enrollments/_doc\")\n",
    "\n",
    "q10_enrollments_df = spark.read.format(\"es\").load(\"enrollments/_doc\")\n",
    "q10_enrollments_df.printSchema()\n",
    "q10_enrollments_df.show(1)\n",
    "q10_enrollments_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40baf832-3a14-45c9-9594-d607439b845a",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Write spark to clear the `neo4j` database of all nodes and relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd7a903e-789b-4b01-8501-6041190b50c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#11 reset neo4j database \n",
    "query = \"\"\"\n",
    "MATCH (n)\n",
    "DETACH DELETE (n);\n",
    "\"\"\"\n",
    "df = spark.createDataFrame(data = [{'row':1}])\n",
    "df.write.format(\"org.neo4j.spark.DataSource\").mode(\"Overwrite\") \\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"query\",query) \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6910199-edde-418d-b6fa-06c5d810ce3d",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Load the `courses` and `program` data into `neo4j` as nodes. Exclude the `requirements`, `electives` and `prerequisites` from the node attributes. Demonstrate the data in `neo4j` by querying back it using one or more Cypher queries. NOTE: the Neo4J `name` attribute is what will display on the node bubbles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71eeb25c-fa18-4702-9595-34f443aca315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- c: struct (nullable = true)\n",
      " |    |-- <id>: long (nullable = false)\n",
      " |    |-- <labels>: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- course_name: string (nullable = true)\n",
      " |    |-- course_credits: long (nullable = true)\n",
      " |    |-- course_description: string (nullable = true)\n",
      " |    |-- _id: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                   c|\n",
      "+--------------------+\n",
      "|{3, [courses], Cl...|\n",
      "|{4, [courses], In...|\n",
      "|{5, [courses], In...|\n",
      "|{6, [courses], Ap...|\n",
      "|{7, [courses], Bi...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#12a load courses into Neo4j\n",
    "# Write to back to Neo4j as nodes with symbol as the key\n",
    "courses_df.select(\"_id\",\n",
    "                   \"course_name\",\n",
    "                   \"course_description\",\n",
    "                   \"course_credits\"\n",
    "                 )\\\n",
    "          .write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "          .mode(\"Overwrite\")\\\n",
    "          .option(\"url\", bolt_url) \\\n",
    "          .option(\"labels\", \"courses\") \\\n",
    "          .option(\"node.keys\",\"course_name\") \\\n",
    "          .save()\n",
    "\n",
    "cipher_read_ql = '''\n",
    "MATCH (c:courses) return c\n",
    "'''\n",
    "#RETURN c.code, c.level, t.semester, f.name, f.title\n",
    "q12a_read_programs = spark.read.format(\"org.neo4j.spark.DataSource\") \\\n",
    "                          .option(\"url\", bolt_url) \\\n",
    "                          .option(\"query\",cipher_read_ql) \\\n",
    "                          .load()\n",
    "q12a_read_programs.printSchema()\n",
    "q12a_read_programs.show(5)\n",
    "q12a_read_programs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f41675f3-16ce-4246-a85b-bf828f92a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- p: struct (nullable = true)\n",
      " |    |-- <id>: long (nullable = false)\n",
      " |    |-- <labels>: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- program_name: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |    |-- program_credits: long (nullable = true)\n",
      " |    |-- _id: string (nullable = true)\n",
      "\n",
      "+--------------------+\n",
      "|                   p|\n",
      "+--------------------+\n",
      "|{8, [programs], I...|\n",
      "|{9, [programs], D...|\n",
      "|{10, [programs], ...|\n",
      "|{11, [programs], ...|\n",
      "|{12, [programs], ...|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#12b load programs into neo4j\n",
    "# Write to back to Neo4j as nodes with symbol as the key\n",
    "programs_df.select(\"_id\",\n",
    "                   \"program_name\",\n",
    "                   \"type\",\n",
    "                   \"program_credits\",\n",
    "                  )\\\n",
    "          .write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "          .mode(\"Overwrite\")\\\n",
    "          .option(\"url\", bolt_url) \\\n",
    "          .option(\"labels\", \"programs\") \\\n",
    "          .option(\"node.keys\",\"program_name\") \\\n",
    "          .save()\n",
    "\n",
    "cipher_read_ql = '''\n",
    "MATCH (p:programs) return p\n",
    "'''\n",
    "#RETURN c.code, c.level, t.semester, f.name, f.title\n",
    "q12b_read_programs = spark.read.format(\"org.neo4j.spark.DataSource\") \\\n",
    "                          .option(\"url\", bolt_url) \\\n",
    "                          .option(\"query\",cipher_read_ql) \\\n",
    "                          .load()\n",
    "q12b_read_programs.printSchema()\n",
    "q12b_read_programs.show(5)\n",
    "q12b_read_programs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5508275-5202-43f5-8adf-773dc22fc681",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "Load the `requirements` and `electives` data into `neo4j` as relationships to the nodes you created in Question 12. Use the `program` data to form the `required` and `elective` course relationships. Demonstrate the relationships in `neo4j` are present by querying back it using one or more Cypher queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f782d89-fa86-4c79-b1f0-baf383c47100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- course_id: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- course_type: string (nullable = true)\n",
      " |-- program_code: string (nullable = true)\n",
      " |-- program_name: string (nullable = true)\n",
      "\n",
      "+---------+--------------------+-----------+------------+-------------------+\n",
      "|course_id|         course_name|course_type|program_code|       program_name|\n",
      "+---------+--------------------+-----------+------------+-------------------+\n",
      "|   IST621|Information Manag...|       Core|          IS|Information Systems|\n",
      "|   IST615|    Cloud Management|       Core|          IS|Information Systems|\n",
      "|   IST659|Data Administrati...|       Core|          IS|Information Systems|\n",
      "|   IST718|  Big Data Analytics|       Core|          DS|       Data Science|\n",
      "|   IST707|Applied Machine L...|       Core|          DS|       Data Science|\n",
      "+---------+--------------------+-----------+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#13a program course requirements\n",
    "# Selecting program_code, elective_courses, and required_courses columns from programs_df\n",
    "q13_programs_df = programs_df.select(\"program_code\",\"elective_courses\",\"required_courses\")\n",
    "\n",
    "# Exploding the required_courses array to get individual required courses\n",
    "q13a_req_programs_df = q13_programs_df.select(\"program_code\",\n",
    "                                               explode_outer(\"required_courses\").alias('required_course'))\n",
    "# Cypher query to create relationships between programs and required courses in Neo4j\n",
    "\n",
    "cipher_ql = '''\n",
    "MATCH (p:programs {_id:event.program_code}), (c:courses {_id:event.required_course})\n",
    "MERGE (p)-[r:Requires{program:event.program_code,course:event.required_course,course_type:\"Core\"}]->(c)\n",
    "'''\n",
    "# Writing the program-course requirements data to Neo4j\n",
    "\n",
    "q13a_req_programs_df.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "                    .mode(\"Overwrite\") \\\n",
    "                    .option(\"url\", bolt_url) \\\n",
    "                    .option(\"query\",cipher_ql) \\\n",
    "                    .save()\n",
    "\n",
    "# Cypher query to read program-course requirements from Neo4j\n",
    "cipher_read_ql = '''\n",
    "MATCH (p:programs)-[r:Requires]->(c:courses) return c._id as course_id,c.course_name as course_name,r.course_type as course_type ,p._id as program_code,p.program_name as program_name\n",
    "'''\n",
    "# Reading program-course requirements data from Neo4j to verify data is loaded correctly\n",
    "q13a_read_programs = spark.read.format(\"org.neo4j.spark.DataSource\") \\\n",
    "                          .option(\"url\", bolt_url) \\\n",
    "                          .option(\"query\",cipher_read_ql) \\\n",
    "                          .load()\n",
    "q13a_read_programs.printSchema()\n",
    "q13a_read_programs.show(5)\n",
    "q13a_read_programs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9abc97bf-a75a-48d9-902a-aae259211e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- course_code: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- course_type: string (nullable = true)\n",
      " |-- program_code: string (nullable = true)\n",
      " |-- program_name: string (nullable = true)\n",
      "\n",
      "+-----------+--------------------+-----------+------------+-------------------+\n",
      "|course_code|         course_name|course_type|program_code|       program_name|\n",
      "+-----------+--------------------+-----------+------------+-------------------+\n",
      "|     IST707|Applied Machine L...|   Elective|          IS|Information Systems|\n",
      "|     IST769|Advanced Big Data...|   Elective|          DS|       Data Science|\n",
      "|     IST714|  Cloud Architecture|   Elective|          DS|       Data Science|\n",
      "|     IST722|    Data Warehousing|   Elective|          IS|Information Systems|\n",
      "|     IST714|  Cloud Architecture|   Elective|          IS|Information Systems|\n",
      "+-----------+--------------------+-----------+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#13b program course electives\n",
    "q13b_req_programs_df = q13_programs_df.select(\"program_code\",\n",
    "                                               explode_outer(\"elective_courses\").alias('elective_courses'))\n",
    "cipher_q2 = '''\n",
    "MATCH (p:programs {_id:event.program_code}), (c:courses {_id:event.elective_courses})\n",
    "MERGE (p)-[r:Elective{program:event.program_code,course:event.elective_courses,course_type:\"Elective\"}]->(c)\n",
    "'''\n",
    "\n",
    "\n",
    "q13b_req_programs_df.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "                    .mode(\"Overwrite\") \\\n",
    "                    .option(\"url\", bolt_url) \\\n",
    "                    .option(\"query\",cipher_q2) \\\n",
    "                    .save()\n",
    "\n",
    "\n",
    "cipher_read_q2 = '''\n",
    "MATCH (p:programs)-[r:Elective]->(c:courses) return c._id as course_code,c.course_name as course_name,r.course_type as course_type,p._id as program_code,p.program_name as program_name\n",
    "'''\n",
    "\n",
    "\n",
    "q13b_read_programs = spark.read.format(\"org.neo4j.spark.DataSource\") \\\n",
    "                          .option(\"url\", bolt_url) \\\n",
    "                          .option(\"query\",cipher_read_q2) \\\n",
    "                          .load()\n",
    "q13b_read_programs.printSchema()\n",
    "q13b_read_programs.show(5)\n",
    "q13b_read_programs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad62a7-505a-4bb8-a2bd-3756cf6719d5",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "\n",
    "Load the `prerequisites` into `neo4j` as relationships to the `course` nodes you created in Question 12. Demonstrate the relationships in `neo4j` are present by querying back it using one or more Cypher queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b9e586b-c5be-4908-bc31-26ab6ef5ba9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- c._id: string (nullable = true)\n",
      " |-- c.course_name: string (nullable = true)\n",
      " |-- pr.course_type: string (nullable = true)\n",
      " |-- pc._id: string (nullable = true)\n",
      " |-- pc.course_name: string (nullable = true)\n",
      "\n",
      "+------+--------------------+--------------+------+--------------------+\n",
      "| c._id|       c.course_name|pr.course_type|pc._id|      pc.course_name|\n",
      "+------+--------------------+--------------+------+--------------------+\n",
      "|IST722|    Data Warehousing|   Prequisites|IST659|Data Administrati...|\n",
      "|IST769|Advanced Big Data...|   Prequisites|IST659|Data Administrati...|\n",
      "|IST714|  Cloud Architecture|   Prequisites|IST615|    Cloud Management|\n",
      "|IST707|Applied Machine L...|   Prequisites|IST687|Introduction to D...|\n",
      "|IST718|  Big Data Analytics|   Prequisites|IST687|Introduction to D...|\n",
      "+------+--------------------+--------------+------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#14 course prerequisites \n",
    "q14_pre_req_courses = courses_df.select(\"course_code\",\n",
    "                                        explode_outer(\"prerequisites\").alias(\"prerequisites\"))\n",
    "#q14_pre_req_courses.filter(q14_pre_req_courses.prerequisites.isNotNull()).show()\n",
    "\n",
    "cipher_q3 = '''\n",
    "MATCH (c:courses{_id:event.course_code}), (pc:courses{_id:event.prerequisites})\n",
    "MERGE (c)-[pr:Requires_Prequisites{course:event.course_code,prequisitescourse:event.prerequisites,course_type:\"Prequisites\"}]->(pc)\n",
    "'''\n",
    "# q14_pre_req_courses.show()\n",
    "q14_pre_req_courses.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "                    .mode(\"Overwrite\") \\\n",
    "                    .option(\"url\", bolt_url) \\\n",
    "                    .option(\"query\",cipher_q3) \\\n",
    "                    .save()\n",
    "\n",
    "cipher_read_q4 = '''\n",
    "MATCH (c:courses)-[pr:Requires_Prequisites]->(pc:courses) return c._id,c.course_name,pr.course_type,pc._id,pc.course_name\n",
    "'''\n",
    "\n",
    "q14_read_programs = spark.read.format(\"org.neo4j.spark.DataSource\") \\\n",
    "                          .option(\"url\", bolt_url) \\\n",
    "                          .option(\"query\",cipher_read_q4) \\\n",
    "                          .load()\n",
    "q14_read_programs.printSchema()\n",
    "q14_read_programs.show(10)\n",
    "q14_read_programs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c4d61d-5076-4d6e-9f54-03e437d18333",
   "metadata": {},
   "source": [
    "### Question 15\n",
    "\n",
    "Write a Cypher query to display courses which are required by both the `IS` and `DS` programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2252e315-eaba-47ee-9f8e-11fc43529c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- course_id: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- course_credits: long (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      "\n",
      "+---------+--------------------+--------------+--------------------+\n",
      "|course_id|         course_name|course_credits|  course_description|\n",
      "+---------+--------------------+--------------+--------------------+\n",
      "|   IST615|    Cloud Management|             3|Cloud services cr...|\n",
      "|   IST659|Data Administrati...|             3|Definition, devel...|\n",
      "+---------+--------------------+--------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#15 Cypher query courses required in DS and IS\n",
    "cipher_read_q5 = '''\n",
    "MATCH (p:programs{_id:'DS'})-[r:Requires]->(c:courses)<-[r1:Requires]-(p1:programs{_id:'IS'}) \n",
    "return c._id as course_id,c.course_name as course_name,c.course_credits as course_credits,c.course_description as course_description\n",
    "'''\n",
    "\n",
    "q14_read_programs = spark.read.format(\"org.neo4j.spark.DataSource\") \\\n",
    "                          .option(\"url\", bolt_url) \\\n",
    "                          .option(\"query\",cipher_read_q5) \\\n",
    "                          .load()\n",
    "q14_read_programs.printSchema()\n",
    "q14_read_programs.show(5)\n",
    "q14_read_programs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe6590-97e2-477f-b860-7ffd5fe63640",
   "metadata": {},
   "source": [
    "### Question 16\n",
    "\n",
    "Write a Cypher query to retrieve the `course code`, `course title`, and the count of programs the course is a requirement in. Write as a Cypher query but retrieve the  output as a Spark Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b68985d-c57c-42b3-87a5-4b9c4b6114f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- course_code: string (nullable = true)\n",
      " |-- course_name: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n",
      "+-----------+--------------------+-----+\n",
      "|course_code|         course_name|count|\n",
      "+-----------+--------------------+-----+\n",
      "|     IST621|Information Manag...|    2|\n",
      "|     IST615|    Cloud Management|    3|\n",
      "|     IST659|Data Administrati...|    3|\n",
      "|     IST718|  Big Data Analytics|    2|\n",
      "|     IST707|Applied Machine L...|    2|\n",
      "|     IST687|Introduction to D...|    2|\n",
      "|     IST722|    Data Warehousing|    1|\n",
      "|     IST769|Advanced Big Data...|    1|\n",
      "|     IST714|  Cloud Architecture|    1|\n",
      "+-----------+--------------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#16 Cypher to spark table\n",
    "cipher_read_q6 = '''\n",
    "MATCH (p:programs)-[r:Requires]->(c:courses) return c._id as course_code,c.course_name as course_name,COUNT(p._id) as count\n",
    "'''\n",
    "\n",
    "q16_read_programs = spark.read.format(\"org.neo4j.spark.DataSource\") \\\n",
    "                          .option(\"url\", bolt_url) \\\n",
    "                          .option(\"query\",cipher_read_q6) \\\n",
    "                          .load()\n",
    "q16_read_programs.printSchema()\n",
    "q16_read_programs.show(10)\n",
    "q16_read_programs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172bc633",
   "metadata": {},
   "source": [
    "### Questions 17,18,19 and 20\n",
    "\n",
    "These are not spark questions as they use kibana."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
